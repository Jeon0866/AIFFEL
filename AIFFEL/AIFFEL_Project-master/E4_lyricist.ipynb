{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "medium-magnet",
   "metadata": {},
   "source": [
    "# 작사가 만들기\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-lawsuit",
   "metadata": {},
   "source": [
    "# 0. 환경"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-labor",
   "metadata": {},
   "source": [
    "* Ubuntu 18.04\n",
    "* TensorFlow 2.4.1\n",
    "* scikit learn 0.23.0\n",
    "* numpy 1.19.5\n",
    "* Keras 2.4.3\n",
    "* conda 4.10.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-charity",
   "metadata": {},
   "source": [
    "# 1. 데이터 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-rouge",
   "metadata": {},
   "source": [
    "* shell 환경에 다운 받아져 있는 데이터 불러오기\n",
    " * mkdir -p ~/aiffel/lyricist/models\n",
    " * ln -s ~/data ~/aiffel/lyricist/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-dimension",
   "metadata": {},
   "source": [
    "# 2. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "endless-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Bidirectional, LSTM, GRU, Dense, Embedding\n",
    "from keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-teaching",
   "metadata": {},
   "source": [
    "* splitlines() = 여러개의 줄로 이루어진 문자열을 한 줄씩 구분하여 리스트 생성, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rural-service",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['At first I was afraid', 'I was petrified', 'I kept thinking I could never live without you']\n"
     ]
    }
   ],
   "source": [
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-arrest",
   "metadata": {},
   "source": [
    "# 3. 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "entertaining-madagascar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At first I was afraid\n",
      "I was petrified\n",
      "I kept thinking I could never live without you\n",
      "By my side But then I spent so many nights\n",
      "Just thinking how you've done me wrong\n",
      "I grew strong\n",
      "I learned how to get along And so you're back\n",
      "From outer space\n",
      "I just walked in to find you\n",
      "Here without that look upon your face I should have changed that fucking lock\n",
      "I would have made you leave your key\n",
      "If I had known for just one second\n",
      "You'd be back to bother me Well now go,\n",
      "Walk out the door\n",
      "Just turn around\n",
      "Now, you're not welcome anymore Weren't you the one\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
    "    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장은 건너뜁니다.\n",
    "\n",
    "    if idx > 15: break   # 문장 확인 \n",
    "        \n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-toolbox",
   "metadata": {},
   "source": [
    "# 3-1. 정규표현식(Regex)을 통한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hourly-camcorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() \n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) \n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) \n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) \n",
    "    sentence = sentence.strip() \n",
    "    sentence = '<start> ' + sentence + ' <end>' \n",
    "    return sentence\n",
    "\n",
    "# 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "green-cancer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> at first i was afraid <end>',\n",
       " '<start> i was petrified <end>',\n",
       " '<start> i kept thinking i could never live without you <end>',\n",
       " '<start> by my side but then i spent so many nights <end>',\n",
       " '<start> just thinking how you ve done me wrong <end>',\n",
       " '<start> i grew strong <end>',\n",
       " '<start> i learned how to get along and so you re back <end>',\n",
       " '<start> from outer space <end>',\n",
       " '<start> i just walked in to find you <end>',\n",
       " '<start> here without that look upon your face i should have changed that fucking lock <end>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여기에 정제된 문장을 모을겁니다\n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    # 우리가 원하지 않는 문장은 건너뜁니다\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    \n",
    "    # 정제를 하고 담아주세요\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "        \n",
    "# 정제된 결과를 10개만 확인해보죠\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-street",
   "metadata": {},
   "source": [
    "# 4. Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-hughes",
   "metadata": {},
   "source": [
    "* maxlen = 15 : 최대 길이를 15까지로 맞춤(0~14개의 index)\n",
    "* truncating = 'post' : 시퀀스의 끝 부분 자름(maxlen과 같이 쓸 수 있음.)\n",
    " * truncating은 pre로 할 경우 시퀀스의 시작 부분을 자름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "impossible-cotton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   71  241 ...    0    0    0]\n",
      " [   2    5   57 ...    0    0    0]\n",
      " [   2    5 1094 ...    0    0    0]\n",
      " ...\n",
      " [   2   48   16 ...    0    0    0]\n",
      " [   2    5   22 ...   32   15   43]\n",
      " [   2    6  180 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7fa1ad49ce90>\n"
     ]
    }
   ],
   "source": [
    "# 토큰화 할 때 텐서플로우의 Tokenizer와 pad_sequences를 사용합니다\n",
    "# 더 잘 알기 위해 아래 문서들을 참고하면 좋습니다\n",
    "def tokenize(corpus):\n",
    "    # 문장을 정제하려면 filters를 사용. 그러나 앞에 정제화를 했기때문에 필요없음\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000,  # 가장 빈도가 높은 num_word개의 단어만 선택\n",
    "        filters=' ',       \n",
    "        oov_token=\"<unk>\" # word_index에 추가, text_to_sequence 호출 중에 어휘 외의 단어를 대체하는 데 사용\n",
    "    )\n",
    "    \n",
    "    # 1. corpus를 이용해 tokenizer 내부의 단어장을 완성합니다.(단어 인덱스 구축)\n",
    "    # 2. 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
    "    # 3. 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n",
    "    # 3. 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
    "    # 3. 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다.\n",
    "    # 3. maxlen=None은 모든 시퀀스의 최대 길이. 제공하지 않으면 시퀀스가 가장 긴 개별 시퀀스의 길이로 채워짐\n",
    "    tokenizer.fit_on_texts(corpus)                                                            # 1\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)                                             # 2   \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, \n",
    "                                                           maxlen=15, \n",
    "                                                           padding='post',\n",
    "                                                           truncating='post')                 # 3\n",
    "                                                             \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incoming-champion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "\n",
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adolescent-skating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2  71 241   5  57 664   3   0   0   0   0   0   0   0]\n",
      "[ 71 241   5  57 664   3   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
    "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "src_input = tensor[:, :-1]  \n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-heating",
   "metadata": {},
   "source": [
    "# 6-1. 데이터셋 분리(train_test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-simon",
   "metadata": {},
   "source": [
    "* 데이터셋을 두가지 방법으로 나누는 방법을 생각했었음.\n",
    "  \n",
    "  전부 사용을 해봤으며 2번으로 정리. \n",
    "\n",
    "1. tf.data.datasets에서 take와 skip\n",
    "2. sklearn.model_selection의 train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "basic-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = dataset.take(124960)    # 데이터셋의 124960개 이후 나머지\n",
    "# test_dataset = dataset.skip(124960)     # 데이터셋의 처음 124960개\n",
    "# print(train_dataset)\n",
    "# print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wrong-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 분리\n",
    "enc_train, enc_val, dec_train, dec_val = \\\n",
    "train_test_split(src_input, tgt_input, test_size=0.2) # shuffle=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-farmer",
   "metadata": {},
   "source": [
    "# 6-2. 데이터셋 분리(tf.data.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "transsexual-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n",
    "# 데이터셋에 대해서는 아래 문서를 참고하세요\n",
    "# 자세히 알아둘수록 도움이 많이 되는 중요한 문서입니다\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
    "# print('# 1 :', dataset)\n",
    "# dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "# print('# 2 :', dataset)\n",
    "# dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "# print('# 3 :', dataset)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "connected-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset이 어떻게 생겼는지 확인\n",
    "# for element in dataset.as_numpy_iterator():\n",
    "#     print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-brunswick",
   "metadata": {},
   "source": [
    "# Hyperparameter Batch_Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-detection",
   "metadata": {},
   "source": [
    "* 전체 데이터를 batch_size 만큼 나누어서 학습시킬 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "crazy-lebanon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "686\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE \n",
    "print(steps_per_epoch)\n",
    " # tokenizer가 구축한 단어사전 내 12000개와, 여기 포함되지 않은 0:<pad>를 포함하여 12001개\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-armor",
   "metadata": {},
   "source": [
    "# 6-3. 진행결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "organized-bruce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140599, 14)\n",
      "(140599, 14)\n",
      "------------------------------\n",
      "(35150, 14)\n",
      "(35150, 14)\n"
     ]
    }
   ],
   "source": [
    "print(enc_train.shape)\n",
    "print(dec_train.shape)\n",
    "print('-'*30)\n",
    "print(enc_val.shape)\n",
    "print(dec_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-delta",
   "metadata": {},
   "source": [
    "# 7. 인공지능 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-genealogy",
   "metadata": {},
   "source": [
    "* 1차 시도(loss = 2.3xx)\n",
    " * 2 LSTM, 1 Dense\n",
    "  * embeding_size = 512, hidden_size = 1024, batch_size = 512\n",
    "* 2차 시도(loss = 2.39x)\n",
    " * 2 GRU, 1 Dense\n",
    "  * embeding_size = 512, hidden_size = 1024, batch_size = 512\n",
    "* 3차 시도(loss = 2.1)\n",
    " * 2 LSTM (dropout= 0.2), 1 Dense\n",
    "  * embeding_size = 512, hidden_size = 1024, batch_size = 512\n",
    "* 4차 시도(loss = 1.8, val_loss = 1.6) \n",
    " * 2 LSTM (dropout = 0.5), 1 Dense\n",
    "  * embeding_size = 256, hidden_size = 1024, batch_size = 512\n",
    "* 5차 시도(loss = 0.012 , test_loss = 0.1946 , val_loss = 0.1908)\n",
    " * 2 Bidirectional LSTM(dropout=0.5), 1 Dense\n",
    "  * embeding_size = 256, hidden_size = 1024, batch_size = 512\n",
    "* n차 시도(loss = 0.07, test_loss = 0.25, val_loss = 0.26 )\n",
    " * 1 LSTM, 1 Bidirectional LSTM, 3 Dropout\n",
    "  * embeding_size = 256, hidden_size = 1024, batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "downtown-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding 층은 두 개의 매개변수를 받음.\n",
    "        self.embedding = Embedding(vocab_size, embedding_size)\n",
    "        self.dropout_1 = Dropout(0.5) \n",
    "        self.rnn_1 = LSTM(hidden_size, return_sequences=True)\n",
    "        self.dropout_2 = Dropout(0.5)\n",
    "        self.rnn_2 = Bidirectional(LSTM(hidden_size, return_sequences=True))\n",
    "        self.dropout_3 = Dropout(0.5)\n",
    "        self.linear = Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.dropout_1(out)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.dropout_2(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.dropout_3(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "embedding_size = 256   # 원래 256\n",
    "hidden_size = 1024     # 원래 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-organizer",
   "metadata": {},
   "source": [
    "* optimizer = Adam 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "conscious-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer, loss\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, # Softmax를 통해 정규화 되지 않은 네트워크의 출력\n",
    "    reduction='none'  # 범주형 교차 엔트로피 label*log(pred)의 각 요소 제공\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "burning-condition",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3296/3296 [==============================] - 495s 148ms/step - loss: 2.4102 - val_loss: 0.7044\n",
      "Epoch 2/10\n",
      "3296/3296 [==============================] - 488s 148ms/step - loss: 0.7235 - val_loss: 0.4551\n",
      "Epoch 3/10\n",
      "3296/3296 [==============================] - 487s 148ms/step - loss: 0.4420 - val_loss: 0.3478\n",
      "Epoch 4/10\n",
      "3296/3296 [==============================] - 486s 148ms/step - loss: 0.2863 - val_loss: 0.2972\n",
      "Epoch 5/10\n",
      "3296/3296 [==============================] - 486s 148ms/step - loss: 0.1987 - val_loss: 0.2756\n",
      "Epoch 6/10\n",
      "3296/3296 [==============================] - 486s 148ms/step - loss: 0.1452 - val_loss: 0.2647\n",
      "Epoch 7/10\n",
      "3296/3296 [==============================] - 485s 147ms/step - loss: 0.1146 - val_loss: 0.2559\n",
      "Epoch 8/10\n",
      "3296/3296 [==============================] - 485s 147ms/step - loss: 0.0950 - val_loss: 0.2558\n",
      "Epoch 9/10\n",
      "3296/3296 [==============================] - 485s 147ms/step - loss: 0.0834 - val_loss: 0.2531\n",
      "Epoch 10/10\n",
      "3296/3296 [==============================] - 485s 147ms/step - loss: 0.0750 - val_loss: 0.2549\n",
      "{'loss': [1.5544320344924927, 0.6643063426017761, 0.42826753854751587, 0.2901078760623932, 0.20793737471103668, 0.15511542558670044, 0.12367558479309082, 0.10397530347108841, 0.09154573082923889, 0.0824613869190216], 'val_loss': [0.7044014930725098, 0.4551209509372711, 0.3478006422519684, 0.2971940040588379, 0.27559900283813477, 0.2647225260734558, 0.25587111711502075, 0.2557660639286041, 0.2531270682811737, 0.25493499636650085]}\n"
     ]
    }
   ],
   "source": [
    "# model.fit\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "history = model.fit(enc_train, dec_train, epochs=10, validation_split=0.25)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-payday",
   "metadata": {},
   "source": [
    "# 8. 시각화(Train / Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-substance",
   "metadata": {},
   "source": [
    "* model.fit에서 진행된 내역을 history 변수에 담아 tf에서 제공하는 history를 통해 epoch당 loss로 시각화\n",
    "* 10 epoch에서 약간의 loss 상승"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "presidential-behavior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train_loss', 'Test_loss'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-external",
   "metadata": {},
   "source": [
    "# 9. 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-distributor",
   "metadata": {},
   "source": [
    "* train_test_split을 통해 나눴던 validation set을 통해 검증\n",
    "* 데이터를 초기 완전 분할했던 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "union-shield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099/1099 [==============================] - 50s 46ms/step - loss: 0.2617\n",
      "Val_loss: 0.2617027163505554\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(enc_val, dec_val)\n",
    "print('Val_loss:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-scanning",
   "metadata": {},
   "source": [
    "# 10. 문장 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "legislative-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    " def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-caution",
   "metadata": {},
   "source": [
    "# 10-1. 다양한 문장 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "developing-outline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> love you , baby <end> '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> love\", max_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "checked-passing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> so many , i m gonna be tough <end> '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> so \", max_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "charming-pixel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you at the corner , i m suppose , i m a '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love \", max_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "clean-madagascar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> boy , i m a caesar <end> '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> boy \", max_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "northern-contractor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> you love me <end> '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> you love\", max_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "worst-maldives",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> every one , i m so sorry <end> '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> every one \", max_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "heard-mentor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> why i m a flirt <end> '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> why\", max_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "adjustable-drawing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> have is that i m not taking <end> '"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> have\", max_len=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-alignment",
   "metadata": {},
   "source": [
    "# 11. 정리 및 생각"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-blood",
   "metadata": {},
   "source": [
    "* 새벽시간대에는 1epoch 당 20~30분씩 걸렸음.\n",
    " * 낮시간은 1epoch 당 7~8분 소요\n",
    "* LSTM의 개선된 모델이 GRU로 알고 있었고 속도적인 측면에서 GRU가 더 좋다고 생각했으나 찾아보고 경험한 결과 다음과 같은 결과를 얻었음.\n",
    " * GRU는 적은 데이터셋에서 빠른속도를 보여줌\n",
    " * LSTM은 많은 데이터에서 적합\n",
    "  * 실제로 둘은 새벽시간대 기준으로 1epoch 당 7~8분 정도의 차이를 보였음.\n",
    "  * 오전/오후시간대 기준으로 평균 3~4분 차이를 보였음\n",
    " * Bidirectional GRU와 Bidirectional LSTM 중 LSTM이 더 빠름\n",
    "* tf.dataset과 train_test_split를 잠깐 비교했을 때 연산속도 차이가 있었음.\n",
    " * batch의 길이가 확연히 차이가 있었음.\n",
    " * tf.dataset은 take와 skip을 통해 데이터를 나눌 수 있었음\n",
    "  * tf.dataset은 train_test_split처럼 나누려면 dataset에서 4개로 쪼개면 됨.(위에서는 2개로만 쪼갬)\n",
    "* vocab 사이즈에 단어가 없는 것인 경우 결과를 확인할 때 unk가 나옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "coral-lesbian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> <unk> <end> '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab에 단어가 없는 경우, 데이터에 없는 맞추기 힘든 단어를 테스트 하였음.\n",
    "generate_text(model, tokenizer, init_sentence=\"<start> Jeon\", max_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "vertical-adult",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> <unk> <end> '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> babuo\", max_len=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-trainer",
   "metadata": {},
   "source": [
    "# 11-1. 최종 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-feelings",
   "metadata": {},
   "source": [
    "* 5차 시도 결과는 4 epochs 이상에서 Overfiting 발생\n",
    " * 3 epochs, val_loss = 0.017 달성\n",
    " * 3 epochs 만으로 과연 패턴이 잘 학습되었다고 볼 수 있을까?(의문)\n",
    " * Bidirectional LSTM layer 1개와 Dense layer\n",
    "* 4차 시도의 모델이 적합.\n",
    " * 10 epochs, val_loss = 1.6 달성\n",
    " * epochs 당 loss가 일정한 속도 떨어졌으며 결과 값도 잘 나왔음. \n",
    " * 똑같은 환경으로 다시 확인했으나 생각보다 잘 나오지 못함.\n",
    " * 이상한 점은 4차시도에서는 val_loss도 잘 떨어졌지만 다시 했을 때 낮게 나오지 못함.\n",
    "* n차 시도\n",
    " * 중도 멈춘 것을 포함해서 총 30번 이상 돌렸음.(1회당 50분~1시간 소요)\n",
    " * 안정적이며 적합하다고 판단하여 제출\n",
    " * loss와 val_loss가 각각 일정하게 떨어짐\n",
    " * dropout을 3개 추가 하여 Overfiting 방지\n",
    " * 생각 외로 긴 문장을 뱉어내지는 못함."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
